{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "score_0_98320.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "23zhBpeINABP"
      },
      "source": [
        "#importer les packages\n",
        "# TensorFlow â‰¥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# To plot pretty figures\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dropout, Dense, Flatten, BatchNormalization, MaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BMx_BAiUeB2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4nWZKHwZ-5j"
      },
      "source": [
        "train_data = np.genfromtxt('/content/drive/My Drive/tp Appren/train_data.csv',delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYd5DaV02dTR"
      },
      "source": [
        "test_data = np.genfromtxt('/content/drive/My Drive/tp Appren/test_data.csv',delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW8jP9i0ChU7"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHN7vrOna6EY"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to-rFSHUUAQl"
      },
      "source": [
        "X_train_full = train_data[:,:-1]\n",
        "y_train_full = train_data[:,-1]\n",
        "X_train_all=np.concatenate((X_train_full,X_train_full,X_train_full,X_train_full,X_train_full,X_train_full,X_train_full,X_train_full,X_train_full,X_train_full), axis=0)\n",
        "y_train_all=np.concatenate((y_train_full,y_train_full,y_train_full,y_train_full,y_train_full,y_train_full,y_train_full,y_train_full,y_train_full,y_train_full), axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxZ_Ugg5r2qJ"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMXEKXuHgU0M"
      },
      "source": [
        "X_train_all.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qJw7IIaAgcW"
      },
      "source": [
        "X_test = test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-8IUrr6AlG_"
      },
      "source": [
        "# Let's transform rows to images\n",
        "X_test = test_data\n",
        "X_train_all = X_train_all.reshape(-1, 28, 28,1)\n",
        "X_test = X_test.reshape(-1, 28, 28,1)\n",
        "\n",
        "X_valid, X_train = X_train_all[80000:] / 255., X_train_all[:80000] / 255.\n",
        "y_valid, y_train = y_train_all[80000:], y_train_all[:80000]\n",
        "X_test = X_test / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0rtliqkAwXW"
      },
      "source": [
        "\"\"\"# **EarlyStopping**\"\"\"\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True,\n",
        "                                                 monitor=\"val_accuracy\",\n",
        "                                                 verbose=1)\n",
        "reduce_lr_plateau = keras.callbacks.ReduceLROnPlateau(patience=2,monitor=\"val_accuracy\",\n",
        "                                                     verbose=1,\n",
        "                                                     factor=0.05,\n",
        "                                                      min_lr=0.000001\n",
        "                                                     )\n",
        "callbacks = [early_stopping_cb, reduce_lr_plateau]\n",
        "                                                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKGw8Citow0U"
      },
      "source": [
        "batch_size = 1024\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "learning_rate = 0.0001\n",
        "model_name = 'model_HMAM'\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = RMSprop(lr=learning_rate)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQSQqfW9LvcN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOzB8_kGA6AW"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "               optimizer= keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08),   \n",
        "              #optimizer= keras.optimizers.Adamax(0.0001), ##keras.optimizers.SGD(0.001),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXpyHeZ2nps7"
      },
      "source": [
        "datagen_train = keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center=True,\n",
        "    #featurewise_std_normalization=True,\n",
        "    rotation_range=5,\n",
        "    width_shift_range=3,\n",
        "    height_shift_range=3,\n",
        "    horizontal_flip=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataget_test = keras.preprocessing.image.ImageDataGenerator(\n",
        "    #featurewise_center=True,\n",
        "    #featurewise_std_normalization=True,\n",
        ")\n",
        "\n",
        "datagen_train.fit(X_train)\n",
        "dataget_test.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYj7sefWBCWV"
      },
      "source": [
        "history = model.fit(datagen_train.flow(X_train, y_train, batch_size=32),\n",
        "          steps_per_epoch=len(X_train) / 32, epochs=200,\n",
        "             validation_data=dataget_test.flow(X_valid, y_valid, batch_size=32),\n",
        "                       callbacks=callbacks)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKS1LxxZoWLM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH6p3dJLBHDW"
      },
      "source": [
        "# Now that we trained the model, we need to make a prediction on a test set, and save into csv\n",
        "predictions = model.predict(X_test)\n",
        "predictions_class = np.argmax(predictions, axis=1)\n",
        "predictions_class\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_XT5XB9BN1m"
      },
      "source": [
        "df_submission = pd.DataFrame(predictions_class, columns = [\"Category\"])\n",
        "df_submission[\"Id\"] = df_submission.index\n",
        "df_submission = df_submission[[\"Id\", \"Category\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Z9cd0rBaRs"
      },
      "source": [
        "df_submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgTqLvfZBeWt"
      },
      "source": [
        "df_submission.to_csv(\"baseline_HMAM38.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP-8y19yvOYq"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vNpthzOvt6K"
      },
      "source": [
        "# Nouvelle section"
      ]
    }
  ]
}